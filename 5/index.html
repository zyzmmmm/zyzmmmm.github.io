<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project 5</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
        }
        .section {
            background: #fff;
            padding: 15px;
            margin: 10px 0;
            border-radius: 5px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
        }
        .image-container {
            display: flex; 
            justify-content: center; 
            gap: 20px; 
        }
        .image-item {
            text-align: center; 
        }
        .image-container p {
            white-space: normal;
        }
    </style>
</head>
<body>
    <!-- Header -->
    <<h1 style="text-align: center;">Project 5: Fun With Diffusion Models!</h1>
    <h2 style="text-align: center;">Yuze Zhang</h2>
    <h2 style="text-align: center;"> Part A</h2>
    <!-- Part 0 -->
    <div class="section">
        <h2 class="section-title">Part 0: Single-Step Denoising UNet</h2>
        <p><strong>Objective:</strong> Train a UNet for single-step denoising using MNIST dataset.</p>
        <p>
            In this part, we will set up the environment to use DeepFloyd, a two-stage diffusion model by Stability AI. To begin, 
            create a Hugging Face account and log in, then accept the license on the DeepFloyd/IF-I-XL-v1.0 model card. Download the precomputed 
            text embeddings to avoid GPU memory issues. The model will generate images from text prompts, with "a high quality photo" 
            serving as a neutral, unconditional prompt for this part. The task is to generate images for three prompts, reflect on the outputs, 
            experiment with num_inference_steps, The random seed is set to YOUR_SEED = 1.
        </p>

        <h3>Test Set Results</h3>
        <div class="image-container">
            <div class="image-item">
                <img src="./media/A/examplenis=20.jpg" alt="Image 1" width="1000px" height="auto">
                <p>Outputs with num_inference_steps=20</p>
            </div>
        </div>

        <div class="image-container">
            <div class="image-item">
                <img src="./media/A/examplenis=50.jpg" alt="Image 1" width="1000px" height="auto">
                <p>Outputs with num_inference_steps=50</p>
            </div>
        </div>
    </div>

    <p>It is evident that clear and detailed text prompts significantly enhance the quality of generated outputs. Furthermore, increasing the 
        value of num_inference_step typically leads to better results. To ensure the reproducibility of these outcomes, the random seed is 
        fixed at 1.</p>

    <!-- Part 1 -->
    <div class="section">
        <h2 class="section-title">Part 1: Single-Step Denoising UNet</h2>
        <p><strong>Objective:</strong> Train a UNet for single-step denoising using MNIST dataset.</p>

        <h3>1.1 Implementing the Forward Process</h3>
        <p>
            In this part, the goal is to implement the forward diffusion process, which progressively adds noise to a clean image. 
            The forward process involves sampling from a Gaussian distribution with  a variance that increases over time. The image 
            is scaled by the cumulative product of alphas (alphas_cumprod), where smaller timesteps result in an image close to the 
            original (less noise) and larger timesteps result in more noise. The task is to write the function noisy_im = forward(im, t), 
            which takes a clean image and a timestep t as inputs, and returns the noisy image at that timestep. The test image, Campanile, 
            is resized to 64x64, and the function is applied to generate noisy images at timesteps [250, 500, 750], which is displayed to 
            observe the progression of noise.
        </p>
        <div class="image-container">
            <div class="image-item">
                <img src="./media/A/origin.jpg" alt="Image 1" width="150px" height="auto">
                <p>original</p>
            </div>
            <div class="image-item">
                <img src="./media/A/noisyt=250.jpg" alt="Image 1" width="150px" height="auto">
                <p>Noisy at t=250</p>
            </div>
            <div class="image-item">
                <img src="./media/A/noisyt=500.jpg" alt="Image 1" width="150px" height="auto">
                <p>Noisy at t=500</p>
            </div>
            <div class="image-item">
                <img src="./media/A/noisyt=750.jpg" alt="Image 1" width="150px" height="auto">
                <p>Noisy at t=750</p>
            </div>
        </div>

        <h3>1.2 Classical Denoising</h3>
        <p>
            In this part, the goal is to apply classical denoising techniques, specifically Gaussian blur filtering, to the noisy images 
            generated at timesteps [250, 500, 750]. Gaussian blur is a smoothing filter that attempts to reduce noise by averaging pixels 
            within a local neighborhood, but it is unlikely to produce good results due to the complexity of noise in the diffusion process. 
            The task is to apply the torchvision.transforms.functional.gaussian_blur function to each noisy image and display the denoised 
            images with the corresponding noisy images. This will illustrate the challenge of denoising these images using traditional methods.
        </p>
        <div class="image-container">
            <div class="image-item">
                <img src="./media/A/noisyt=250.jpg" alt="Image 1" width="150px" height="auto">
                <p>Noisy Image at t=250</p>
            </div>
            <div class="image-item">
                <img src="./media/A/noisyt=500.jpg" alt="Image 1" width="150px" height="auto">
                <p>Noisy Image at t=500</p>
            </div>
            <div class="image-item">
                <img src="./media/A/noisyt=750.jpg" alt="Image 1" width="150px" height="auto">
                <p>Noisy Image at t=750</p>
            </div>
        </div>

        <div class="image-container">
            <div class="image-item">
                <img src="./media/A/blurt=250.jpg" alt="Image 1" width="150px" height="auto">
                <p>Gaussian Blur Denoising<br> Image at t=250</p>
            </div>
            <div class="image-item">
                <img src="./media/A/blurt=500.jpg" alt="Image 1" width="150px" height="auto">
                <p>Gaussian Blur Denoising<br> Image at t=500</p>
            </div>
            <div class="image-item">
                <img src="./media/A/blurt=750.jpg" alt="Image 1" width="150px" height="auto">
                <p>Gaussian Blur Denoising<br> Image t=750</p>
            </div>
        </div>

        <h3>1.3 One-Step Denoising</h3>
        <p>
            Part 1.3 involves using the pretrained UNet model to denoise noisy images generated at timesteps [250, 500, 750]. The model 
            estimates the noise in the image based on the timestep and a provided text prompt embedding. The noisy image is passed through 
            the UNet to predict the noise, which is then removed to recover an estimate of the original image. The denoised image, along 
            with the original and noisy images, are visualized for comparison. 
        </p>

        <div class="image-container">
            <div class="image-item">
                <img src="./media/A/origin.jpg" alt="Image 1" width="150px" height="auto">
                <p>Original</p>
            </div>
            <div class="image-item">
                <img src="./media/A/noisyt=250.jpg" alt="Image 1" width="150px" height="auto">
                <p>Noisy Image at t=250</p>
            </div>
            <div class="image-item">
                <img src="./media/A/noisyt=500.jpg" alt="Image 1" width="150px" height="auto">
                <p>Noisy Image at t=500</p>
            </div>
            <div class="image-item">
                <img src="./media/A/noisyt=750.jpg" alt="Image 1" width="150px" height="auto">
                <p>Noisy Image at t=750</p>
            </div>
        </div>
        
        <div class="image-container">
            <div class="image-item">
                <img src="./media/A/origin.jpg" alt="Image 1" width="150px" height="auto">
                <p>Original</p>
            </div>
            <div class="image-item">
                <img src="./media/A/t=250.jpg" alt="Image 1" width="150px" height="auto">
                <p>One Step Denoising<br> Image at t=250</p>
            </div>
            <div class="image-item">
                <img src="./media/A/t=500.jpg" alt="Image 1" width="150px" height="auto">
                <p>One Step Denoising<br> Image at t=500</p>
            </div>
            <div class="image-item">
                <img src="./media/A/t=750.jpg" alt="Image 1" width="150px" height="auto">
                <p>One Step Denoising<br> Image t=750</p>
            </div>
        </div>

        <p>The U-Net can be effective to some extent, but as ùë° increases, the sampling results deteriorate.</p>

        <h3>1.4 Iterative Denoising</h3>
        <p>
            Part 1.4 focuses on implementing iterative denoising for diffusion models. Instead of running the model 1000 times, 
            the process can be sped up by skipping steps. The goal is to create a list of timesteps (strided_timesteps), starting at the 
            noisiest image and reducing the noise with Unet step by step. The formula for each denoising step involves a interpolation between 
            the noisy image and a clean image estimate, adjusting for the noise at each timestep.
        </p>
        <div class="image-container">
            <div class="image-item">
                <img src="./media/A/cleant=690istart=10.jpg" alt="Image 1" width="150px" height="auto">
                <p>Noisy Image at t=690</p>
            </div>
            <div class="image-item">
                <img src="./media/A/cleant=540istart=10.jpg" alt="Image 1" width="150px" height="auto">
                <p>Noisy Image at t=540</p>
            </div>
            <div class="image-item">
                <img src="./media/A/cleant=390istart=10.jpg" alt="Image 1" width="150px" height="auto">
                <p>Noisy Image at t=390</p>
            </div>
            <div class="image-item">
                <img src="./media/A/cleant=240istart=10.jpg" alt="Image 1" width="150px" height="auto">
                <p>Noisy Image at t=240</p>
            </div>
            <div class="image-item">
                <img src="./media/A/cleant=90istart=10.jpg" alt="Image 1" width="150px" height="auto">
                <p>Noisy Image at t=90</p>
            </div>
        </div>

        <div class="image-container">
            <div class="image-item">
                <img src="./media/A/origin.jpg" alt="Image 1" width="150px" height="auto">
                <p>Original</p>
            </div>
            <div class="image-item">
                <img src="./media/A/cleant=0istart=10.jpg" alt="Image 1" width="150px" height="auto">
                <p>Iterative Denoising<br> Image</p>
            </div>
            <div class="image-item">
                <img src="./media/A/cleanonestepistart=10.jpg" alt="Image 1" width="150px" height="auto">
                <p>One Step Denoising<br> Image</p>
            </div>
            <div class="image-item">
                <img src="./media/A/bluristart=10.jpg" alt="Image 1" width="150px" height="auto">
                <p>Gaussian Blurred<br> Denoising Image</p>
            </div>
        </div>

        <h3>1.5 Diffusion Model Sampling</h3>
        <p>
            Part 1.5 involves using the iterative_denoise function to generate images from scratch by denoising random noise. By setting 
            i_start = 0 and initializing the image with pure noise, the model progressively refines the noisy image into a coherent result. 
            The task requires generating 5 images based on the prompt "a high quality photo."
        </p>
        <div class="image-container">
            <div class="image-item">
                <img src="./media/A/randomsample0.jpg" alt="Image 1" width="150px" height="auto">
                <p>Sample 1</p>
            </div>
            <div class="image-item">
                <img src="./media/A/randomsample1.jpg" alt="Image 1" width="150px" height="auto">
                <p>Sample 2</p>
            </div>
            <div class="image-item">
                <img src="./media/A/randomsample2.jpg" alt="Image 1" width="150px" height="auto">
                <p>Sample 3</p>
            </div>
            <div class="image-item">
                <img src="./media/A/randomsample3.jpg" alt="Image 1" width="150px" height="auto">
                <p>Sample 4</p>
            </div>
            <div class="image-item">
                <img src="./media/A/randomsample4.jpg" alt="Image 1" width="150px" height="auto">
                <p>Sample 5</p>
            </div>
        </div>

        <h3>1.6 Classifier-Free Guidance (CFG)</h3>
        <p>
            Part 1.6 focuses on improving image quality through Classifier-Free Guidance (CFG). CFG enhances the diffusion process by 
            computing both conditional and unconditional noise estimates. The final noise estimate is a weighted combination of these 
            two, by using model_output = scale * noise_est + (1 - scale) * uncond_noise_est. This technique improves the quality of generated 
            images but reduces their diversity.
        <div class="image-container">
            <div class="image-item">
                <img src="./media/A/randomsamplecfg0.jpg" alt="Image 1" width="150px" height="auto">
                <p>Sample with CFG 1</p>
            </div>
            <div class="image-item">
                <img src="./media/A/randomsamplecfg1.jpg" alt="Image 1" width="150px" height="auto">
                <p>Sample with CFG 2</p>
            </div>
            <div class="image-item">
                <img src="./media/A/randomsamplecfg2.jpg" alt="Image 1" width="150px" height="auto">
                <p>Sample with CFG 3</p>
            </div>
            <div class="image-item">
                <img src="./media/A/randomsamplecfg3.jpg" alt="Image 1" width="150px" height="auto">
                <p>Sample with CFG 4</p>
            </div>
            <div class="image-item">
                <img src="./media/A/randomsamplecfg4.jpg" alt="Image 1" width="150px" height="auto">
                <p>Sample with CFG 5</p>
            </div>
        </div>

        <p>The sampling results using CFG are much better than the previous sampling results.</p>

        <h3>1.7 Image-to-image Translation</h3>
        <p>
            Part 1.7 focuses on image-to-image translation using the diffusion model with Classifier-Free Guidance (CFG). The goal is to take a noisy 
            version of a test image and iteratively denoise it, gradually making the image resemble the original with varying levels of noise. 
            This process is based on the SDEdit algorithm, which forces a noisy image back onto the manifold of natural images, allowing for creative edits.
        </p>
        <h4>Test Image</h4>
        <div class="image-container">
            <div class="image-item">
                <img src="./media/A/SDEditistart=1.jpg" alt="Image 1" width="120px" height="auto">
                <p>SDEdit i_start=1</p>
            </div>
            <div class="image-item">
                <img src="./media/A/SDEditistart=3.jpg" alt="Image 1" width="120px" height="auto">
                <p>SDEdit i_start=3</p>
            </div>
            <div class="image-item">
                <img src="./media/A/SDEditistart=5.jpg" alt="Image 1" width="120px" height="auto">
                <p>SDEdit i_start=5</p>
            </div>
            <div class="image-item">
                <img src="./media/A/SDEditistart=7.jpg" alt="Image 1" width="120px" height="auto">
                <p>SDEdit i_start=7</p>
            </div>
            <div class="image-item">
                <img src="./media/A/SDEditistart=10.jpg" alt="Image 1" width="120px" height="auto">
                <p>SDEdit i_start=10</p>
            </div>
            <div class="image-item">
                <img src="./media/A/SDEditistart=20.jpg" alt="Image 1" width="120px" height="auto">
                <p>SDEdit i_start=20</p>
            </div>
            <div class="image-item">
                <img src="./media/A/origin.jpg" alt="Image 1" width="120px" height="auto">
                <p>Original</p>
            </div>
        </div>
        <h4>Own Image</h4>
        <div class="image-container">
            <div class="image-item">
                <img src="./media/A/SDEditownout1t.jpg" alt="Image 1" width="800px" height="auto">
                <p>SDEdit starting from different i_start</p>
            </div>
            <div class="image-item">
                <img src="./media/A/SDEditown1.jpg" alt="Image 1" width="190px" height="auto">
                <p>Original</p>
            </div>
        </div>

        <div class="image-container">
            <div class="image-item">
                <img src="./media/A/SDEditownout2t.jpg" alt="Image 1" width="800px" height="auto">
                <p>SDEdit starting from different i_start</p>
            </div>
            <div class="image-item">
                <img src="./media/A/SDEditown2.jpg" alt="Image 1" width="190px" height="auto">
                <p>Original</p>
            </div>
        </div>

        <h4>1.7.1 Editing Hand-Drawn and Web Images</h4>
        <p>
            Part 1.7.1 focuses on applying the image-to-image translation procedure to hand-drawn or non-realistic images, such as sketches or web images, 
            to project them onto the natural image manifold.
        </p>
        <h5>Web Image</h5>
        <div class="image-container">
            <div class="image-item">
                <img src="./media/A/webimistart=1.jpg" alt="Image 1" width="120px" height="auto">
                <p>Image at i_start=1</p>
            </div>
            <div class="image-item">
                <img src="./media/A/webimistart=3.jpg" alt="Image 1" width="120px" height="auto">
                <p>Image at i_start=3</p>
            </div>
            <div class="image-item">
                <img src="./media/A/webimistart=5.jpg" alt="Image 1" width="120px" height="auto">
                <p>Image at i_start=5</p>
            </div>
            <div class="image-item">
                <img src="./media/A/webimistart=7.jpg" alt="Image 1" width="120px" height="auto">
                <p>Image at i_start=7</p>
            </div>
            <div class="image-item">
                <img src="./media/A/webimistart=10.jpg" alt="Image 1" width="120px" height="auto">
                <p>Image at i_start=10</p>
            </div>
            <div class="image-item">
                <img src="./media/A/webimistart=20.jpg" alt="Image 1" width="120px" height="auto">
                <p>Image at i_start=20</p>
            </div>
            <div class="image-item">
                <img src="./media/A/webim.jpg" alt="Image 1" width="120px" height="auto">
                <p>Image from Website</p>
            </div>
        </div>

        <div class="image-container">
            <div class="image-item">
                <img src="./media/A/webim2istart=1.jpg" alt="Image 1" width="120px" height="auto">
                <p>Image at i_start=1</p>
            </div>
            <div class="image-item">
                <img src="./media/A/webim2istart=3.jpg" alt="Image 1" width="120px" height="auto">
                <p>Image at i_start=3</p>
            </div>
            <div class="image-item">
                <img src="./media/A/webim2istart=5.jpg" alt="Image 1" width="120px" height="auto">
                <p>Image at i_start=5</p>
            </div>
            <div class="image-item">
                <img src="./media/A/webim2istart=7.jpg" alt="Image 1" width="120px" height="auto">
                <p>Image at i_start=7</p>
            </div>
            <div class="image-item">
                <img src="./media/A/webim2istart=10.jpg" alt="Image 1" width="120px" height="auto">
                <p>Image at i_start=10</p>
            </div>
            <div class="image-item">
                <img src="./media/A/webim2istart=20.jpg" alt="Image 1" width="120px" height="auto">
                <p>Image at i_start=20</p>
            </div>
            <div class="image-item">
                <img src="./media/A/webim2.jpg" alt="Image 1" width="120px" height="auto">
                <p>Image from Website</p>
            </div>
        </div>
        <h5>Hand Drawn Image</h5>
        <div class="image-container">
            <div class="image-item">
                <img src="./media/A/draw1istart=1.jpg" alt="Image 1" width="120px" height="auto">
                <p>Image at i_start=1</p>
            </div>
            <div class="image-item">
                <img src="./media/A/draw1istart=3.jpg" alt="Image 1" width="120px" height="auto">
                <p>Image at i_start=3</p>
            </div>
            <div class="image-item">
                <img src="./media/A/draw1istart=5.jpg" alt="Image 1" width="120px" height="auto">
                <p>Image at i_start=5</p>
            </div>
            <div class="image-item">
                <img src="./media/A/draw1istart=7.jpg" alt="Image 1" width="120px" height="auto">
                <p>Image at i_start=7</p>
            </div>
            <div class="image-item">
                <img src="./media/A/draw1istart=10.jpg" alt="Image 1" width="120px" height="auto">
                <p>Image at i_start=10</p>
            </div>
            <div class="image-item">
                <img src="./media/A/draw1istart=20.jpg" alt="Image 1" width="120px" height="auto">
                <p>Image at i_start=20</p>
            </div>
            <div class="image-item">
                <img src="./media/A/draw1.jpg" alt="Image 1" width="120px" height="auto">
                <p>Hand Drawn Image</p>
            </div>
        </div>

        <div class="image-container">
            <div class="image-item">
                <img src="./media/A/draw2istart=1.jpg" alt="Image 1" width="120px" height="auto">
                <p>Image at i_start=1</p>
            </div>
            <div class="image-item">
                <img src="./media/A/draw2istart=3.jpg" alt="Image 1" width="120px" height="auto">
                <p>Image at i_start=3</p>
            </div>
            <div class="image-item">
                <img src="./media/A/draw2istart=5.jpg" alt="Image 1" width="120px" height="auto">
                <p>Image at i_start=5</p>
            </div>
            <div class="image-item">
                <img src="./media/A/draw2istart=7.jpg" alt="Image 1" width="120px" height="auto">
                <p>Image at i_start=7</p>
            </div>
            <div class="image-item">
                <img src="./media/A/draw2istart=10.jpg" alt="Image 1" width="120px" height="auto">
                <p>Image at i_start=10</p>
            </div>
            <div class="image-item">
                <img src="./media/A/draw2istart=20.jpg" alt="Image 1" width="120px" height="auto">
                <p>Image at i_start=20</p>
            </div>
            <div class="image-item">
                <img src="./media/A/draw2.jpg" alt="Image 1" width="120px" height="auto">
                <p>Hand Drawn Image</p>
            </div>
        </div>

        <h4>1.7.2 Inpainting</h4>
        <p>      
            In part 1.7.2, the task is to implement inpainting using the diffusion model. The goal is to take an image ùë•0, a binary mask ùëö, 
            and create a new image that retains the content of ùë•0 where ùëö=0 (the unmasked areas), but fills in the masked areas (where ùëö=1) 
            with new content generated by the model. The specific method is to replace the parts with a mask value of 0 with the corresponding 
            noisy image from the original image at time step t after each denoising step.
        </p>
        <h5>Test Image</h5>

        <div class="image-container">
            <div class="image-item">
                <img src="./media/A/origin.jpg" alt="Image 1" width="150px" height="auto">
                <p>Original</p>
            </div>
            <div class="image-item">
                <img src="./media/A/mask.jpg" alt="Image 1" width="150px" height="auto">
                <p>Mask</p>
            </div>
            <div class="image-item">
                <img src="./media/A/toreplace.jpg" alt="Image 1" width="150px" height="auto">
                <p>To Replace</p>
            </div>
            <div class="image-item">
                <img src="./media/A/testinpaint.jpg" alt="Image 1" width="150px" height="auto">
                <p>Inpainting</p>
            </div>
        </div>
        
        <h5>Own Image</h5>
        <div class="image-container">
            <div class="image-item">
                <img src="./media/A/inpaintingown1.jpg" alt="Image 1" width="150px" height="auto">
                <p>Original</p>
            </div>
            <div class="image-item">
                <img src="./media/A/mask1.jpg" alt="Image 1" width="150px" height="auto">
                <p>Mask</p>
            </div>
            <div class="image-item">
                <img src="./media/A/toreplace1.jpg" alt="Image 1" width="150px" height="auto">
                <p>To Replace</p>
            </div>
            <div class="image-item">
                <img src="./media/A/inpaintingownout1.jpg" alt="Image 1" width="150px" height="auto">
                <p>Inpainting</p>
            </div>
        </div>

        <div class="image-container">
            <div class="image-item">
                <img src="./media/A/inpaintingown2.jpg" alt="Image 1" width="150px" height="auto">
                <p>Original</p>
            </div>
            <div class="image-item">
                <img src="./media/A/mask2.jpg" alt="Image 1" width="150px" height="auto">
                <p>Mask</p>
            </div>
            <div class="image-item">
                <img src="./media/A/toreplace2.jpg" alt="Image 1" width="150px" height="auto">
                <p>To Replace</p>
            </div>
            <div class="image-item">
                <img src="./media/A/inpaintingownout2.jpg" alt="Image 1" width="150px" height="auto">
                <p>Inpainting</p>
            </div>
        </div>

        <h4>1.7.3 Text-Conditional Image-to-image Translation</h4>
        <p>      
            In part 1.7.3, the task is to apply text-conditional image-to-image translation. This is similar to the previous SDEdit approach but now includes 
            a text prompt to guide the process. The goal is to generate images that not only project onto the natural image manifold but also incorporate 
            the characteristics of the provided text prompt.
        </p>

        <h5>Test Image</h5>
        <div class="image-container">
            <div class="image-item">
                <img src="./media/A/image2imagetranst.jpg" alt="Image 1" width="800px" height="auto">
                <p>Text-Conditional Image-to-image Translation ("a rocket ship")</p>
            </div>
            <div class="image-item">
                <img src="./media/A/origin.jpg" alt="Image 1" width="190px" height="auto">
                <p>Original</p>
            </div>
        </div>

        <h5>Own Image</h5>
        <div class="image-container">
            <div class="image-item">
                <img src="./media/A/image2imageownout1.jpg" alt="Image 1" width="800px" height="auto">
                <p>Text-Conditional Image-to-image Translation ("an oil painting of a snowy mountain village")</p>
            </div>
            <div class="image-item">
                <img src="./media/A/image2imageown1.jpg" alt="Image 1" width="190px" height="auto">
                <p>Original</p>
            </div>
        </div>

        <div class="image-container">
            <div class="image-item">
                <img src="./media/A/image2imageownout2.jpg" alt="Image 1" width="800px" height="auto">
                <p>Text-Conditional Image-to-image Translation ("a photo of a dog")</p>
            </div>
            <div class="image-item">
                <img src="./media/A/image2imageown2.jpg" alt="Image 1" width="190px" height="auto">
                <p>Original</p>
            </div>
        </div>

        <h3>1.8 Visual Anagrams</h3>
        <p>
            In part 1.8, the task is to implement Visual Anagrams‚Äîa technique that creates optical illusions using diffusion models. 
            The goal is to generate an image that appears as one thing when viewed in one orientation but transforms into something 
            completely different when flipped upside down. The method involves estimating the noise of the image at each time step t 
            and its vertically flipped version. The estimated noise is obtained by averaging the original noise with the flipped 
            version after it is reversed.
        </p>

        <h4>Example</h4>
        <div class="image-container">
            <div class="image-item">
                <img src="./media/A/vaup.jpg" alt="Image 1" width="300px" height="auto">
                <p>An Oil Painting of an Old Man</p>
            </div>
            <div class="image-item">
                <img src="./media/A/vadown.jpg" alt="Image 1" width="300px" height="auto">
                <p>An Oil Painting of People around a Campfire</p>
            </div>
        </div>

        <h4>More Examples</h4>
        <div class="image-container">
            <div class="image-item">
                <img src="./media/A/vaup1.jpg" alt="Image 1" width="300px" height="auto">
                <p>A Photo of A Dog</p>
            </div>
            <div class="image-item">
                <img src="./media/A/vadown1.jpg" alt="Image 1" width="300px" height="auto">
                <p>A Man Wearing A Hat</p>
            </div>
        </div>

        <div class="image-container">
            <div class="image-item">
                <img src="./media/A/vaup2.jpg" alt="Image 1" width="300px" height="auto">
                <p>A Photo of A Hipster Barista</p>
            </div>
            <div class="image-item">
                <img src="./media/A/vadown2.jpg" alt="Image 1" width="300px" height="auto">
                <p>A Lithograph of Waterfalls</p>
            </div>
        </div>

        <h3>1.9 Hybrid Images</h3>
        <p>
            In part 1.9, the task is to create Hybrid Images using diffusion models. Hybrid images combine the low-frequency content 
            from one image with the high-frequency content from another, producing an image that looks like one thing from a distance 
            and something completely different up close. The estimated noise is obtained by combining the low-frequency noise estimation 
            of one image with the high-frequency noise estimation of another image.
        </p>

        <h4>Example</h4>
        <div class="image-container">
            <div class="image-item">
                <img src="./media/A/hybrids.jpg" alt="Image 1" width="400px" height="auto">
                <p>Hybrid image of a skull and a waterfall</p>
            </div>
        </div>

        <h4>More Examples</h4>

        <div class="image-container">
            <div class="image-item">
                <img src="./media/A/hybrids1.jpg" alt="Image 1" width="400px" height="auto">
                <p>Hybrid image of a man and a skull</p>
            </div>
        </div>

        <div class="image-container">
            <div class="image-item">
                <img src="./media/A/hybrids2.jpg" alt="Image 1" width="400px" height="auto">
                <p>Hybrid image of a man and a dog</p>
            </div>
        </div>
        
    </div>

    
    <hr>
    
    
    <h2 style="text-align: center;"> Part B</h2>
    <!-- Part 1 -->
   <div class="section">
        <h2 class="section-title">Part 1: Single-Step Denoising UNet</h2>
        <p><strong>Objective:</strong> Train a UNet for single-step denoising using MNIST dataset.</p>
        <p>
            The first part of the project focuses on training a UNet model to perform single-step denoising on the MNIST dataset. 
            The objective is to restore clean images from noisy counterparts that have been corrupted with Gaussian noise. 
            This task involves preparing the MNIST dataset by adding noise to simulate real-world degradations. A UNet architecture is then designed 
            to learn the mapping from noisy to clean images. During training, the model minimizes the mean squared error between the predicted and ground truth images. 
            The results are evaluated by comparing denoised outputs at different stages of training, visualizing the loss curve, and testing the model on noise levels unseen during training. 
            The outcomes demonstrate the UNet's ability to effectively learn and improve its denoising performance over time.
        </p>

        <h3>Visualization of Noising Process</h3>
        <div class="image-container">
            <div class="image-item">
                <img src="./media/B/noisingprocessings.jpg" alt="Image 1" width="1000px" height="auto">
                <p>Noise on MNIST</p>
            </div>
        </div>

        <h3>Training Loss Curve</h3>
        <div class="image-container">
            <div class="image-item">
                <img src="./media/B/lossfuncepoch=5.jpg" alt="Image 1" width="500px" height="auto">
                <p>Training Loss with epoch=5</p>
            </div>
            <div class="image-item">
                <img src="./media/B/lossfuncepoch=1.jpg" alt="Image 1" width="500px" height="auto">
                <p>Training Loss with epoch=1</p>
            </div>
        </div>

        <h3>Test Set Results</h3>
        <div class="image-container">
            <div class="image-item">
                <img src="./media/B/onestepdenoiseepoch=1.jpg" alt="Results After 1 Epoch" width="500px" height="auto">
                <p>Results on digits from the test set after 1 epoch of training</p>
            </div>
            <div class="image-item">
                <img src="./media/B/onestepdenoiseepoch=5.jpg" alt="Results After 5 Epochs" width="500px" height="auto">
                <p>Results on digits from the test set after 5 epoch of training</p>
            </div>
        </div>

        <h3>Out-of-Distribution Testing</h3>
        <div class="image-container">
            <div class="image-item">
                <img src="./media/B/outofdistribution.jpg" alt="Image 1" width="1000px" height="auto">
                <p>Results on digits from the test set with varying noise levels</p>
            </div>
        </div>
    </div>

    <!-- Part 2 -->
    <div class="section">
        <h2 class="section-title">Part 2: Training a Diffusion Model</h2>
        <p><strong>Objective:</strong> Train a time-conditioned UNet to iteratively denoise images.</p>
        <p>
            In the second part, a time-conditioned UNet is trained to iteratively denoise images as part of a diffusion model framework. 
            The key idea is to generate a sequence of noisy images by progressively adding Gaussian noise, 
            then train the model to reverse this process step by step. The UNet incorporates a time-conditioning mechanism, 
            allowing it to denoise images based on the noise level at a given timestep. The model is trained to minimize the 
            difference between its predictions and the clean images, enabling it to reconstruct high-quality samples from noisy inputs. 
            Training progress is tracked using a loss curve, while the quality of generated images is evaluated by sampling outputs at 
            different stages of training. These results illustrate the model's ability to iteratively improve the image quality through 
            the denoising process.
        </p>

        <h3>Training Loss Curve</h3>
        <div class="image-container">
            <div class="image-item">
                <img src="./media/B/timecondlossfuncepoch=5.jpg" alt="Image 1" width="500px" height="auto">
                <p>Time-Conditioned UNet training loss curve with epoch=5</p>
            </div>
            <div class="image-item">
                <img src="./media/B/timecondlossfuncepoch=20.jpg" alt="Image 1" width="500px" height="auto">
                <p>Time-Conditioned UNet training loss curve with epoch=20</p>
            </div>
        </div>

        <h3>Sampling Results</h3>
        <div class="image-container">
            <div class="image-item">
                <img src="./media/B/timecondoutepoch=5.jpg" alt="Diffusion Results After 5 Epochs" width="500px" height="auto">
                <p>Diffusion Results After 5 Epochs</p>
            </div>
            <div class="image-item">
                <img src="./media/B/timecondoutepoch=20.jpg" alt="Diffusion Results After 20 Epochs" width="500px" height="auto">
                <p>Diffusion Results After 20 Epochs</p>
            </div>
        </div>

        <!-- Optional: Class-Conditioned UNet -->
        <h3 class="section-title">Class-Conditioned UNet</h2>
        <p><strong>Objective:</strong> Train a class-conditioned UNet with classifier-free guidance.</p>
        <p>
            The final part of the project extends the diffusion model by introducing class conditioning, where the model is guided to generate outputs corresponding to specific classes. 
            This is achieved by incorporating one-hot encoded class labels as an additional input to the UNet model. 
            During training, the model learns to associate noisy images with their respective class labels, 
            allowing it to produce class-specific results during sampling. To further enhance the generated outputs, 
            classifier-free guidance is applied, encouraging the model to better focus on class-related features. 
            The effectiveness of this approach is evaluated by generating samples for each class at different training stages, 
            with visualizations showcasing the diversity and accuracy of the generated images.
        </p>

        <h3>Training Loss Curve</h3>
        <div class="image-container">
            <div class="image-item">
                <img src="./media/B/classcondlossfuncepoch=5.jpg" alt="Image 1" width="500px" height="auto">
                <p>Class-Conditioned UNet training loss curve with epoch=5</p>
            </div>
            <div class="image-item">
                <img src="./media/B/classcondlossfuncepoch=20.jpg" alt="Image 1" width="500px" height="auto">
                <p>Class-Conditioned UNet training loss curve with epoch=20</p>
            </div>
        </div>

        <h3>Sampling Results</h3>
        <div class="image-container">
            <div class="image-item">
                <img src="./media/B/classcondoutepoch=5.jpg" alt="Diffusion Results After 5 Epochs" width="500px" height="auto">
                <p>Diffusion Results After 5 Epochs</p>
            </div>
            <div class="image-item">
                <img src="./media/B/classcondoutepoch=20.jpg" alt="Diffusion Results After 20 Epochs" width="500px" height="auto">
                <p>Diffusion Results After 20 Epochs</p>
            </div>
        </div>
    </div>

    <div class="section">
        <h2>Bells & Whistles</h2>
        <h3>time condition diffusion gif</h3>
        <div class="image-container">
            <div class="image-item">
                <img src="./media/B/timecondepoch=1.gif" alt="Diffusion Results After 5 Epochs" width="500px" height="auto">
                <p>Time Condition Diffusion Results After 1 Epochs</p>
            </div>
            <div class="image-item">
                <img src="./media/B/timecondepoch=20.gif" alt="Diffusion Results After 20 Epochs" width="500px" height="auto">
                <p>Time Condition Diffusion Results After 20 Epochs</p>
            </div>
        </div>
        <h3>class condition diffusion gif</h3>
        <div class="image-container">
            <div class="image-item">
                <img src="./media/B/classcondepoch=1.gif" alt="Diffusion Results After 5 Epochs" width="500px" height="auto">
                <p>Class Condition Diffusion Results After 1 Epochs</p>
            </div>
            <div class="image-item">
                <img src="./media/B/classcondepoch=20.gif" alt="Diffusion Results After 20 Epochs" width="500px" height="auto">
                <p>Class Condition Diffusion Results After 20 Epochs</p>
            </div>
        </div>
    </div>


        
</body>
</html>

