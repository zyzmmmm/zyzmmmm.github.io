<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project 5</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
        }
        .section {
            background: #fff;
            padding: 15px;
            margin: 10px 0;
            border-radius: 5px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
        }
        .image-container {
            display: flex; 
            justify-content: center; 
            gap: 20px; 
        }
        .image-item {
            text-align: center; 
        }
    </style>
</head>
<body>
    <!-- Header -->
    <header class="text-center mb-5">
        <h1>Fun With Diffusion Models!</h1>
        <p class="lead">CS180: Introduction to Computer Vision and Computational Photography</p>
        <p class="lead">Yuze Zhang</p>
    </header>
    <h2 style="text-align: center;"> Part A</h2>
    <!-- Part 0 -->
    <div class="section">
        <h2 class="section-title">Part 0: Single-Step Denoising UNet</h2>
        <p><strong>Objective:</strong> Train a UNet for single-step denoising using MNIST dataset.</p>
        <p>
            In this part, we will set up the environment to use DeepFloyd, a two-stage diffusion model by Stability AI. To begin, 
            create a Hugging Face account and log in, then accept the license on the DeepFloyd/IF-I-XL-v1.0 model card. Download the precomputed 
            text embeddings to avoid GPU memory issues, especially when using free Colab resources. The model will generate images from text 
            prompts, with "a high quality photo" serving as a neutral, unconditional prompt for this part. Your task is to generate images 
            for three prompts, reflect on the outputs, experiment with num_inference_steps, and report the random seed used for generation.
        </p>

        <h3>Test Set Results</h3>
        <div class="image-container">
            <div class="image-item">
                <img src="./out/A/examplenis=20.jpg" alt="Image 1" width="1000px" height="auto">
                <p>Outputs with num_inference_steps=20</p>
            </div>
        </div>

        <div class="image-container">
            <div class="image-item">
                <img src="./out/A/examplenis=50.jpg" alt="Image 1" width="1000px" height="auto">
                <p>Outputs with num_inference_steps=50</p>
            </div>
        </div>
    </div>
    

    <!-- Part 1 -->
    <div class="section">
        <h2 class="section-title">Part 1: Single-Step Denoising UNet</h2>
        <p><strong>Objective:</strong> Train a UNet for single-step denoising using MNIST dataset.</p>

        <h3>1.1 Implementing the Forward Process</h3>
        <p>
            In this part, the goal is to implement the forward diffusion process, which progressively adds noise to a clean image. 
            The forward process involves sampling from a Gaussian distribution with mean proportional to the clean image and a variance 
            that increases over time. The image is scaled by the cumulative product of alphas (alphas_cumprod), where smaller timesteps 
            result in an image close to the original (less noise) and larger timesteps result in more noise. The task is to write the function 
            noisy_im = forward(im, t), which takes a clean image and a timestep t as inputs, and returns the noisy image at that timestep. 
            The test image, Campanile, should be resized to 64x64, and the function should be applied to generate noisy images at 
            timesteps [250, 500, 750], which should be displayed to observe the progression of noise.
        </p>
        <div class="image-container">
            <div class="image-item">
                <img src="./out/A/origin.jpg" alt="Image 1" width="150px" height="auto">
                <p>original</p>
            </div>
            <div class="image-item">
                <img src="./out/A/noisyt=250.jpg" alt="Image 1" width="150px" height="auto">
                <p>Noisy at t=250</p>
            </div>
            <div class="image-item">
                <img src="./out/A/noisyt=500.jpg" alt="Image 1" width="150px" height="auto">
                <p>Noisy at t=500</p>
            </div>
            <div class="image-item">
                <img src="./out/A/noisyt=750.jpg" alt="Image 1" width="150px" height="auto">
                <p>Noisy at t=750</p>
            </div>
        </div>

        <h3>1.2 Classical Denoising</h3>
        <p>
            n this part, the goal is to apply classical denoising techniques, specifically Gaussian blur filtering, to the noisy images 
            generated in the previous step (at timesteps [250, 500, 750]). Gaussian blur is a smoothing filter that attempts to reduce 
            noise by averaging pixels within a local neighborhood, but it is unlikely to produce good results due to the complexity of 
            noise in the diffusion process. The task is to apply the torchvision.transforms.functional.gaussian_blur function to each noisy 
            image and display the denoised images side by side with the corresponding noisy images. This will illustrate the challenge 
            of denoising these images using traditional methods.
        </p>
        <div class="image-container">
            <div class="image-item">
                <img src="./out/A/noisyt=250.jpg" alt="Image 1" width="150px" height="auto">
                <p>Noisy Image at t=250</p>
            </div>
            <div class="image-item">
                <img src="./out/A/noisyt=500.jpg" alt="Image 1" width="150px" height="auto">
                <p>Noisy Image at t=500</p>
            </div>
            <div class="image-item">
                <img src="./out/A/noisyt=750.jpg" alt="Image 1" width="150px" height="auto">
                <p>Noisy Image at t=750</p>
            </div>
        </div>

        <div class="image-container">
            <div class="image-item">
                <img src="./out/A/blurt=250.jpg" alt="Image 1" width="150px" height="auto">
                <p>Gaussian Blur Denoising Image at t=250</p>
            </div>
            <div class="image-item">
                <img src="./out/A/blurt=500.jpg" alt="Image 1" width="150px" height="auto">
                <p>Gaussian Blur Denoising Image at t=500</p>
            </div>
            <div class="image-item">
                <img src="./out/A/blurt=750.jpg" alt="Image 1" width="150px" height="auto">
                <p>Gaussian Blur Denoising Image t=750</p>
            </div>
        </div>

        <h3>1.3 One-Step Denoising</h3>
        <p>
            Part 1.3 involves using the pretrained UNet model (stage_1.unet) to denoise noisy images generated at timesteps [250, 500, 750]. 
            The model estimates the noise in the image based on the timestep and a provided text prompt embedding. The noisy image is passed 
            through the UNet to predict the noise, which is then removed to recover an estimate of the original image. The denoised image, along 
            with the original and noisy images, should be visualized for comparison. Ensure tensors are on the correct device and use 
            torch.no_grad() for memory efficiency.
        </p>

        <div class="image-container">
            <div class="image-item">
                <img src="./out/A/noisyt=250.jpg" alt="Image 1" width="150px" height="auto">
                <p>Noisy Image at t=250</p>
            </div>
            <div class="image-item">
                <img src="./out/A/noisyt=500.jpg" alt="Image 1" width="150px" height="auto">
                <p>Noisy Image at t=500</p>
            </div>
            <div class="image-item">
                <img src="./out/A/noisyt=750.jpg" alt="Image 1" width="150px" height="auto">
                <p>Noisy Image at t=750</p>
            </div>
        </div>
        
        <div class="image-container">
            <div class="image-item">
                <img src="./out/A/t=250.jpg" alt="Image 1" width="150px" height="auto">
                <p>One Step Denoising Image at t=250</p>
            </div>
            <div class="image-item">
                <img src="./out/A/t=500.jpg" alt="Image 1" width="150px" height="auto">
                <p>One Step Denoising Image at t=500</p>
            </div>
            <div class="image-item">
                <img src="./out/A/t=750.jpg" alt="Image 1" width="150px" height="auto">
                <p>One Step Denoising Image t=750</p>
            </div>
        </div>

        <h3>1.4 Iterative Denoising</h3>
        <p>
            Part 1.4 focuses on implementing iterative denoising for diffusion models. Instead of running the model 1000 times, the process can 
            be sped up by skipping steps. The goal is to create a list of timesteps (strided_timesteps), starting at the noisiest image and reducing 
            the noise step by step. The formula for each denoising step involves a linear interpolation between the noisy image and a clean image 
            estimate, adjusting for the noise at each timestep.
        </p>
        <div class="image-container">
            <div class="image-item">
                <img src="./out/A/cleant=690istart=10.jpg" alt="Image 1" width="150px" height="auto">
                <p>Noisy Image at t=690</p>
            </div>
            <div class="image-item">
                <img src="./out/A/cleant=540istart=10.jpg" alt="Image 1" width="150px" height="auto">
                <p>Noisy Image at t=540</p>
            </div>
            <div class="image-item">
                <img src="./out/A/cleant=390istart=10.jpg" alt="Image 1" width="150px" height="auto">
                <p>Noisy Image at t=390</p>
            </div>
            <div class="image-item">
                <img src="./out/A/cleant=240istart=10.jpg" alt="Image 1" width="150px" height="auto">
                <p>Noisy Image at t=240</p>
            </div>
            <div class="image-item">
                <img src="./out/A/cleant=90istart=10.jpg" alt="Image 1" width="150px" height="auto">
                <p>Noisy Image at t=90</p>
            </div>
        </div>

        <div class="image-container">
            <div class="image-item">
                <img src="./out/A/origin.jpg" alt="Image 1" width="150px" height="auto">
                <p>Original</p>
            </div>
            <div class="image-item">
                <img src="./out/A/cleant=0istart=10.jpg" alt="Image 1" width="150px" height="auto">
                <p>Iterative Denoising Image</p>
            </div>
            <div class="image-item">
                <img src="./out/A/cleanonestepistart=10.jpg" alt="Image 1" width="150px" height="auto">
                <p>One Step Denoising Image</p>
            </div>
            <div class="image-item">
                <img src="./out/A/bluristart=10.jpg" alt="Image 1" width="150px" height="auto">
                <p>Gaussian Blurred Denoising Image</p>
            </div>
        </div>

        <h3>1.5 Diffusion Model Sampling</h3>
        <p>
            Part 1.5 involves using the iterative_denoise function to generate images from scratch by denoising random noise. 
            By setting i_start = 0 and initializing the image with pure noise, the model progressively refines the noisy image 
            into a coherent result. The task requires generating 5 images based on the prompt "a high quality photo."
        </p>
        <div class="image-container">
            <div class="image-item">
                <img src="./out/A/randomsample0.jpg" alt="Image 1" width="150px" height="auto">
                <p>Sample 1</p>
            </div>
            <div class="image-item">
                <img src="./out/A/randomsample1.jpg" alt="Image 1" width="150px" height="auto">
                <p>Sample 2</p>
            </div>
            <div class="image-item">
                <img src="./out/A/randomsample2.jpg" alt="Image 1" width="150px" height="auto">
                <p>Sample 3</p>
            </div>
            <div class="image-item">
                <img src="./out/A/randomsample3.jpg" alt="Image 1" width="150px" height="auto">
                <p>Sample 4</p>
            </div>
            <div class="image-item">
                <img src="./out/A/randomsample4.jpg" alt="Image 1" width="150px" height="auto">
                <p>Sample 5</p>
            </div>
        </div>

        <h3>1.6 Classifier-Free Guidance (CFG)</h3>
        <p>
            Part 1.6 focuses on improving image quality through Classifier-Free Guidance (CFG). CFG enhances the diffusion process 
            by computing both conditional and unconditional noise estimates. The final noise estimate is a weighted combination of these two, 
            with the weighting controlled by the CFG scale. This technique improves the quality of generated images but reduces their diversity.
        </p>
        <div class="image-container">
            <div class="image-item">
                <img src="./out/A/randomsamplecfg0.jpg" alt="Image 1" width="150px" height="auto">
                <p>Sample with CFG 1</p>
            </div>
            <div class="image-item">
                <img src="./out/A/randomsamplecfg1.jpg" alt="Image 1" width="150px" height="auto">
                <p>Sample with CFG 2</p>
            </div>
            <div class="image-item">
                <img src="./out/A/randomsamplecfg2.jpg" alt="Image 1" width="150px" height="auto">
                <p>Sample with CFG 3</p>
            </div>
            <div class="image-item">
                <img src="./out/A/randomsamplecfg3.jpg" alt="Image 1" width="150px" height="auto">
                <p>Sample with CFG 4</p>
            </div>
            <div class="image-item">
                <img src="./out/A/randomsamplecfg4.jpg" alt="Image 1" width="150px" height="auto">
                <p>Sample with CFG 5</p>
            </div>
        </div>

        <h3>1.7 Image-to-image Translation</h3>
        <p>
            Part 1.7 focuses on image-to-image translation using the diffusion model with Classifier-Free Guidance (CFG). The goal is to take a noisy 
            version of a test image and iteratively denoise it, gradually making the image resemble the original with varying levels of noise. 
            This process is based on the SDEdit algorithm, which forces a noisy image back onto the manifold of natural images, allowing for creative edits.
        </p>
        <div class="image-container">
            <div class="image-item">
                <img src="./out/A/SDEditistart=1.jpg" alt="Image 1" width="150px" height="auto">
                <p>SDEdit i_start=1</p>
            </div>
            <div class="image-item">
                <img src="./out/A/SDEditistart=3.jpg" alt="Image 1" width="150px" height="auto">
                <p>SDEdit i_start=3</p>
            </div>
            <div class="image-item">
                <img src="./out/A/SDEditistart=5.jpg" alt="Image 1" width="150px" height="auto">
                <p>SDEdit i_start=5</p>
            </div>
            <div class="image-item">
                <img src="./out/A/SDEditistart=7.jpg" alt="Image 1" width="150px" height="auto">
                <p>SDEdit i_start=7</p>
            </div>
            <div class="image-item">
                <img src="./out/A/SDEditistart=10.jpg" alt="Image 1" width="150px" height="auto">
                <p>SDEdit i_start=10</p>
            </div>
            <div class="image-item">
                <img src="./out/A/SDEditistart=20.jpg" alt="Image 1" width="150px" height="auto">
                <p>SDEdit i_start=20</p>
            </div>
            <div class="image-item">
                <img src="./out/A/origin.jpg" alt="Image 1" width="150px" height="auto">
                <p>Original</p>
            </div>
        </div>

        <h4>1.7.1 Editing Hand-Drawn and Web Images</h4>
        <p>
            Part 1.7.1 focuses on applying the image-to-image translation procedure to hand-drawn or non-realistic images, such as sketches or web images, 
            to project them onto the natural image manifold.
        </p>
        <div class="image-container">
            <div class="image-item">
                <img src="./out/A/webimistart=1.jpg" alt="Image 1" width="150px" height="auto">
                <p>Image at i_start=1</p>
            </div>
            <div class="image-item">
                <img src="./out/A/webimistart=3.jpg" alt="Image 1" width="150px" height="auto">
                <p>Image at i_start=3</p>
            </div>
            <div class="image-item">
                <img src="./out/A/webimistart=5.jpg" alt="Image 1" width="150px" height="auto">
                <p>Image at i_start=5</p>
            </div>
            <div class="image-item">
                <img src="./out/A/webimistart=7.jpg" alt="Image 1" width="150px" height="auto">
                <p>Image at i_start=7</p>
            </div>
            <div class="image-item">
                <img src="./out/A/webimistart=10.jpg" alt="Image 1" width="150px" height="auto">
                <p>Image at i_start=10</p>
            </div>
            <div class="image-item">
                <img src="./out/A/webimistart=20.jpg" alt="Image 1" width="150px" height="auto">
                <p>Image at i_start=20</p>
            </div>
            <div class="image-item">
                <img src="./out/A/webim.jpg" alt="Image 1" width="150px" height="auto">
                <p>Image from Website</p>
            </div>
        </div>

        <div class="image-container">
            <div class="image-item">
                <img src="./out/A/webim2istart=1.jpg" alt="Image 1" width="150px" height="auto">
                <p>Image at i_start=1</p>
            </div>
            <div class="image-item">
                <img src="./out/A/webim2istart=3.jpg" alt="Image 1" width="150px" height="auto">
                <p>Image at i_start=3</p>
            </div>
            <div class="image-item">
                <img src="./out/A/webim2istart=5.jpg" alt="Image 1" width="150px" height="auto">
                <p>Image at i_start=5</p>
            </div>
            <div class="image-item">
                <img src="./out/A/webim2istart=7.jpg" alt="Image 1" width="150px" height="auto">
                <p>Image at i_start=7</p>
            </div>
            <div class="image-item">
                <img src="./out/A/webim2istart=10.jpg" alt="Image 1" width="150px" height="auto">
                <p>Image at i_start=10</p>
            </div>
            <div class="image-item">
                <img src="./out/A/webim2istart=20.jpg" alt="Image 1" width="150px" height="auto">
                <p>Image at i_start=20</p>
            </div>
            <div class="image-item">
                <img src="./out/A/webim2.jpg" alt="Image 1" width="150px" height="auto">
                <p>Image from Website</p>
            </div>
        </div>

        <div class="image-container">
            <div class="image-item">
                <img src="./out/A/draw1istart=1.jpg" alt="Image 1" width="150px" height="auto">
                <p>Image at i_start=1</p>
            </div>
            <div class="image-item">
                <img src="./out/A/draw1istart=3.jpg" alt="Image 1" width="150px" height="auto">
                <p>Image at i_start=3</p>
            </div>
            <div class="image-item">
                <img src="./out/A/draw1istart=5.jpg" alt="Image 1" width="150px" height="auto">
                <p>Image at i_start=5</p>
            </div>
            <div class="image-item">
                <img src="./out/A/draw1istart=7.jpg" alt="Image 1" width="150px" height="auto">
                <p>Image at i_start=7</p>
            </div>
            <div class="image-item">
                <img src="./out/A/draw1istart=10.jpg" alt="Image 1" width="150px" height="auto">
                <p>Image at i_start=10</p>
            </div>
            <div class="image-item">
                <img src="./out/A/draw1istart=20.jpg" alt="Image 1" width="150px" height="auto">
                <p>Image at i_start=20</p>
            </div>
            <div class="image-item">
                <img src="./out/A/draw1.jpg" alt="Image 1" width="150px" height="auto">
                <p>Hand Drawn Image</p>
            </div>
        </div>

        <div class="image-container">
            <div class="image-item">
                <img src="./out/A/draw2istart=1.jpg" alt="Image 1" width="150px" height="auto">
                <p>Image at i_start=1</p>
            </div>
            <div class="image-item">
                <img src="./out/A/draw2istart=3.jpg" alt="Image 1" width="150px" height="auto">
                <p>Image at i_start=3</p>
            </div>
            <div class="image-item">
                <img src="./out/A/draw2istart=5.jpg" alt="Image 1" width="150px" height="auto">
                <p>Image at i_start=5</p>
            </div>
            <div class="image-item">
                <img src="./out/A/draw2istart=7.jpg" alt="Image 1" width="150px" height="auto">
                <p>Image at i_start=7</p>
            </div>
            <div class="image-item">
                <img src="./out/A/draw2istart=10.jpg" alt="Image 1" width="150px" height="auto">
                <p>Image at i_start=10</p>
            </div>
            <div class="image-item">
                <img src="./out/A/draw2istart=20.jpg" alt="Image 1" width="150px" height="auto">
                <p>Image at i_start=20</p>
            </div>
            <div class="image-item">
                <img src="./out/A/draw2.jpg" alt="Image 1" width="150px" height="auto">
                <p>Hand Drawn Image</p>
            </div>
        </div>

        <h4>1.7.2 Inpainting</h4>
        <p>      
            In part 1.7.2, the task is to implement inpainting using the diffusion model, following the RePaint paper. The goal is to take an image ùë•0, 
            a binary mask ùëö, and create a new image that retains the content of ùë•0 where ùëö=0 (the unmasked areas), but fills in the masked areas 
            (where ùëö=1) with new content generated by the model.
        </p>
        <div class="row">
            <div class="col-md-6">
                <h4>After 1 Epoch</h4>
                <img src="figure5_results_epoch1.png" alt="Results After 1 Epoch">
            </div>
            <div class="col-md-6">
                <h4>After 5 Epochs</h4>
                <img src="figure6_results_epoch5.png" alt="Results After 5 Epochs">
            </div>
        </div>

        <h4>1.7.3 Text-Conditional Image-to-image Translation</h4>
        <p>      
            In part 1.7.3, the task is to apply text-conditional image-to-image translation. This is similar to the previous SDEdit approach but now includes 
            a text prompt to guide the process. The goal is to generate images that not only project onto the natural image manifold but also incorporate 
            the characteristics of the provided text prompt.
        </p>
        <div class="row">
            <div class="col-md-6">
                <h4>After 1 Epoch</h4>
                <img src="figure5_results_epoch1.png" alt="Results After 1 Epoch">
            </div>
            <div class="col-md-6">
                <h4>After 5 Epochs</h4>
                <img src="figure6_results_epoch5.png" alt="Results After 5 Epochs">
            </div>
        </div>

        <h3>1.8 Visual Anagrams</h3>
        <p>
            In part 1.8, the task is to implement Visual Anagrams‚Äîa technique that creates optical illusions using diffusion models. The goal is to generate 
            an image that appears as one thing when viewed in one orientation but transforms into something completely different when flipped upside down.
        </p>
        <div class="image-container">
            <div class="image-item">
                <img src="./out/A/vaup.jpg" alt="Image 1" width="300px" height="auto">
                <p>An Oil Painting of an Old Man</p>
            </div>
            <div class="image-item">
                <img src="./out/A/vadown.jpg" alt="Image 1" width="300px" height="auto">
                <p>An Oil Painting of People around a Campfire</p>
            </div>
        </div>

        <h3>1.9 Hybrid Images</h3>
        <p>
            In part 1.9, the task is to create Hybrid Images using diffusion models. Hybrid images combine the low-frequency content from one image with 
            the high-frequency content from another, producing an image that looks like one thing from a distance and something completely different up close.
        </p>
        <div class="image-container">
            <div class="image-item">
                <img src="./out/A/hybrids.jpg" alt="Image 1" width="700px" height="auto">
                <p>Hybrid image of a skull and a waterfall</p>
            </div>
        </div>
        
    </div>

    
    <hr>
    
    
    <h2 style="text-align: center;"> Part B</h2>
    <!-- Part 1 -->
   <div class="section">
        <h2 class="section-title">Part 1: Single-Step Denoising UNet</h2>
        <p><strong>Objective:</strong> Train a UNet for single-step denoising using MNIST dataset.</p>
        <p>
            The first part of the project focuses on training a UNet model to perform single-step denoising on the MNIST dataset. 
            The objective is to restore clean images from noisy counterparts that have been corrupted with Gaussian noise. 
            This task involves preparing the MNIST dataset by adding noise to simulate real-world degradations. A UNet architecture is then designed 
            to learn the mapping from noisy to clean images. During training, the model minimizes the mean squared error between the predicted and ground truth images. 
            The results are evaluated by comparing denoised outputs at different stages of training, visualizing the loss curve, and testing the model on noise levels unseen during training. 
            The outcomes demonstrate the UNet's ability to effectively learn and improve its denoising performance over time.
        </p>

        <h3>Visualization of Noising Process</h3>
        <div class="image-container">
            <div class="image-item">
                <img src="./out/B/noisingprocessings.jpg" alt="Image 1" width="1000px" height="auto">
                <p>Noise on MNIST</p>
            </div>
        </div>

        <h3>Training Loss Curve</h3>
        <div class="image-container">
            <div class="image-item">
                <img src="./out/B/lossfuncepoch=5.jpg" alt="Image 1" width="1000px" height="auto">
                <p>Training Loss with epoch=5</p>
            </div>
        </div>

       <div class="image-container">
            <div class="image-item">
                <img src="./out/B/lossfuncepoch=1.jpg" alt="Image 1" width="1000px" height="auto">
                <p>Training Loss with epoch=1</p>
            </div>
        </div>

        <h3>Test Set Results</h3>
        <div class="row">
            <div class="col-md-6">
                <img src="onestepdenoiseepoch=1.jpg" alt="Results After 1 Epoch" width=700 height="auto">
                <p>Results on digits from the test set after 1 epoch of training</p>
            </div>
            <div class="col-md-6">
                <img src="onestepdenoiseepoch=5.jpg" alt="Results After 5 Epochs" width=700 height="auto">
                <p>Results on digits from the test set after 5 epoch of training</p>
            </div>
        </div>

        <h3>Out-of-Distribution Testing</h3>
        <div class="image-container">
            <div class="image-item">
                <img src="./out/B/outofdistribution.jpg" alt="Image 1" width="1000px" height="auto">
                <p>Results on digits from the test set with varying noise levels</p>
            </div>
        </div>
    </div>

    <!-- Part 2 -->
    <div class="section">
        <h2 class="section-title">Part 2: Training a Diffusion Model</h2>
        <p><strong>Objective:</strong> Train a time-conditioned UNet to iteratively denoise images.</p>
        <p>
            In the second part, a time-conditioned UNet is trained to iteratively denoise images as part of a diffusion model framework. 
            The key idea is to generate a sequence of noisy images by progressively adding Gaussian noise, 
            then train the model to reverse this process step by step. The UNet incorporates a time-conditioning mechanism, 
            allowing it to denoise images based on the noise level at a given timestep. The model is trained to minimize the 
            difference between its predictions and the clean images, enabling it to reconstruct high-quality samples from noisy inputs. 
            Training progress is tracked using a loss curve, while the quality of generated images is evaluated by sampling outputs at 
            different stages of training. These results illustrate the model's ability to iteratively improve the image quality through the denoising process.
        </p>

        <h3>Training Loss Curve</h3>
        <div class="image-container">
            <div class="image-item">
                <img src="./out/B/timecondlossfuncepoch=5.jpg" alt="Image 1" width="700px" height="auto">
                <p>Time-Conditioned UNet training loss curve with epoch=5</p>
            </div>
            <div class="image-item">
                <img src="./out/B/timecondlossfuncepoch=20.jpg" alt="Image 1" width="700px" height="auto">
                <p>Time-Conditioned UNet training loss curve with epoch=20</p>
            </div>
        </div>

        <h3>Sampling Results</h3>
        <div class="image-container">
            <div class="image-item">
                <img src=".out/B/timecondoutepoch=5.jpg" alt="Diffusion Results After 5 Epochs" width="700px" height="auto">
                <p>Diffusion Results After 5 Epochs</p>
            </div>
            <div class="image-item">
                <img src=".out/B/timecondoutepoch=20.jpg" alt="Diffusion Results After 20 Epochs" width="700px" height="auto">
                <p>Diffusion Results After 20 Epochs</p>
            </div>
        </div>

        <!-- Optional: Class-Conditioned UNet -->
        <h3 class="section-title">Class-Conditioned UNet</h2>
        <p><strong>Objective:</strong> Train a class-conditioned UNet with classifier-free guidance.</p>
        <p>
            The final part of the project extends the diffusion model by introducing class conditioning, where the model is guided to generate outputs corresponding to specific classes. 
            This is achieved by incorporating one-hot encoded class labels as an additional input to the UNet model. 
            During training, the model learns to associate noisy images with their respective class labels, 
            allowing it to produce class-specific results during sampling. To further enhance the generated outputs, 
            classifier-free guidance is applied, encouraging the model to better focus on class-related features. 
            The effectiveness of this approach is evaluated by generating samples for each class at different training stages, 
            with visualizations showcasing the diversity and accuracy of the generated images.
        </p>

        <h3>Training Loss Curve</h3>
        <div class="image-container">
            <div class="image-item">
                <img src="./out/B/classcondlossfuncepoch=5.jpg" alt="Image 1" width="700px" height="auto">
                <p>Class-Conditioned UNet training loss curve with epoch=5</p>
            </div>
            <div class="image-item">
                <img src="./out/B/classcondlossfuncepoch=20.jpg" alt="Image 1" width="700px" height="auto">
                <p>Class-Conditioned UNet training loss curve with epoch=20</p>
            </div>
        </div>

        <h3>Sampling Results</h3>
        <div class="image-container">
            <div class="image-item">
                <img src=".out/B/classcondoutepoch=5.jpg" alt="Diffusion Results After 5 Epochs" width="700px" height="auto">
                <p>Diffusion Results After 5 Epochs</p>
            </div>
            <div class="image-item">
                <img src=".out/B/classcondoutepoch=20.jpg" alt="Diffusion Results After 20 Epochs" width="700px" height="auto">
                <p>Diffusion Results After 20 Epochs</p>
            </div>
        </div>
    </div>

</body>
</html>

